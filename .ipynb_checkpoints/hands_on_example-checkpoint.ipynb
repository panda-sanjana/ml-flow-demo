{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "* P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "* Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/wine-quality.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tracking experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking stores\n",
    "MLflow supports two types of backend stores: *file store* and *database-backed* store.\n",
    "\n",
    "- Local file path (specified as file:/my/local/dir), where data is just directly stored locally. Defaults to `mlruns/`\n",
    "- Database encoded as <dialect>+<driver>://<username>:<password>@<host>:<port>/<database>. Mlflow supports the dialects mysql, mssql, sqlite, and postgresql. For more details, see SQLAlchemy database uri.\n",
    "- HTTP server (specified as https://my-server:5000), which is a server hosting an MLFlow tracking server.\n",
    "- Databricks workspace (specified as databricks or as databricks://<profileName>, a Databricks CLI profile.\n",
    "    \n",
    "### Artifact stores\n",
    "- Amazon S3\n",
    "- Azure Blob Storage\n",
    "- Google Cloud Storage\n",
    "- FTP server\n",
    "- SFTP Server\n",
    "- NFS\n",
    "- HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the MLflow tracking server by \n",
    "\n",
    "```\n",
    "mlflow server \\\n",
    "    --backend-store-uri /mnt/persistent-disk \\\n",
    "    --default-artifact-root s3://my-mlflow-bucket/ \\\n",
    "    --host 0.0.0.0\n",
    "    --port 5000\n",
    "```\n",
    "\n",
    "or use the default storage method to write to `mlruns/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0 --port 1234\u001b[39;00m\n\u001b[1;32m      2\u001b[0m remote_server_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://0.0.0.0:1234\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# set to your server URI\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241m.\u001b[39mset_tracking_uri(remote_server_uri)  \u001b[38;5;66;03m# or set the MLFLOW_TRACKING_URI in the env\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlflow' is not defined"
     ]
    }
   ],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0 --port 1234\n",
    "remote_server_uri = \"http://0.0.0.0:1234\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tracking.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"ElasticNet_wine\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we track?\n",
    "\n",
    "- **Code Version**: Git commit hash used for the run (if it was run from an MLflow Project)\n",
    "- **Start & End Time**: Start and end time of the run\n",
    "- **Source**: what code run?\n",
    "- **Parameters**: Key-value input parameters.\n",
    "- **Metrics**: Key-value metrics, where the value is numeric (can be updated over the run)\n",
    "- **Artifacts**: Output files in any format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    # compute relevant metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([\"quality\"], axis=1)\n",
    "    test_x = test.drop([\"quality\"], axis=1)\n",
    "    train_y = train[[\"quality\"]]\n",
    "    test_y = test[[\"quality\"]]\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def train(alpha=0.5, l1_ratio=0.5):\n",
    "    # train a model with given parameters\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(40)\n",
    "\n",
    "    # Read the wine-quality csv file (make sure you're running this from the root of MLflow!)\n",
    "    data_path = \"data/wine-quality.csv\"\n",
    "    train_x, train_y, test_x, test_y = load_data(data_path)\n",
    "\n",
    "    # Useful for multiple runs (only doing one run in this sample notebook)    \n",
    "    with mlflow.start_run():\n",
    "        # Execute ElasticNet\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        # Evaluate Metrics\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        # Print out metrics\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(key=\"alpha\", value=alpha)\n",
    "        mlflow.log_param(key=\"l1_ratio\", value=l1_ratio)\n",
    "        mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "        mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "        mlflow.log_artifact(data_path)\n",
    "        print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "        \n",
    "        mlflow.sklearn.log_model(lr, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also do\n",
    "# with mlflow.start_run():\n",
    "#     for epoch in range(0, 3):\n",
    "#          mlflow.log_metric(key=\"quality\", value=2*epoch, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Comparing runs\n",
    "Run `mlflow ui` in a terminal or `http://your-tracking-server-host:5000` to view the experiment log and visualize and compare different runs and experiments. The logs and the model artifacts are saved in the `mlruns` directory (or where you specified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Packaging the experiment as a MLflow project as conda env\n",
    "\n",
    "Specify the entrypoint for this project by creating a `MLproject` file and adding an conda environment with a `conda.yaml`. You can copy the yaml file from the experiment logs.\n",
    "\n",
    "To run this project, invoke `mlflow run . -P alpha=0.42`. After running this command, MLflow runs your training code in a new Conda environment with the dependencies specified in `conda.yaml`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy the model\n",
    "\n",
    "Deploy the model locally by running \n",
    "\n",
    "`mlflow models serve -m mlruns/0/f5f7c052ddc5469a852aa52c14cabdf1/artifacts/model/ -h 0.0.0.0 -p 1234`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the endpoint:\n",
    "\n",
    "`curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data '{\"columns\":[\"alcohol\", \"chlorides\", \"citric acid\", \"density\", \"fixed acidity\", \"free sulfur dioxide\", \"pH\", \"residual sugar\", \"sulphates\", \"total sulfur dioxide\", \"volatile acidity\"],\"data\":[[12.8, 0.029, 0.48, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75, 0.66]]}' http://0.0.0.0:1234/invocations`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also simply build a docker image from your model\n",
    "\n",
    "`mlflow models build-docker -m mlruns/1/d671f37a9c7f478989e67eb4ff4d1dac/artifacts/model/ -n elastic_net_wine`\n",
    "\n",
    "and run the container with\n",
    "\n",
    "`docker run -p 8080:8080 elastic_net_wine`.\n",
    "\n",
    "Or you can directly deploy to AWS sagemaker or Microsoft Azure ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tagging runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiments = client.list_experiments() # returns a list of mlflow.entities.Experiment\n",
    "print(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the run\n",
    "_run = client.get_run(run_id=\"3627a8dd69d14bee919205e5e69c8bca\")\n",
    "print(_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a tag to the run\n",
    "dt = datetime.now().strftime(\"%d-%m-%Y (%H:%M:%S.%f)\")\n",
    "client.set_tag(_run.info.run_id, \"deployed\", dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to a postgesql db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the db:\n",
    "    \n",
    "`sudo -u postgres psql`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a user and a database for the tracking server:\n",
    "    \n",
    "```\n",
    "CREATE DATABASE mlflow;\n",
    "CREATE USER mlflow WITH ENCRYPTED PASSWORD 'mlflow';\n",
    "GRANT ALL PRIVILEGES ON DATABASE mlflow TO mlflow;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "mlflow server --backend-store-uri postgresql://mlflow:mlflow@localhost/mlflow --default-artifact-root file:/home/tobias/Projects/mlflow_talk/pydataberlin-2019/mlruns/ -h 0.0.0.0 -p 8000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the notebook again with this tracking server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the db:\n",
    "\n",
    "`psql mlflow`\n",
    "\n",
    "`SELECT * FROM experiments;`\n",
    "\n",
    "`SELECT * FROM runs;`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
